import { cache } from './cache';\n\ninterface PerformanceMetric {\n  name: string;\n  value: number;\n  timestamp: number;\n  tags?: Record<string, string>;\n}\n\ninterface QueryPerformance {\n  query: string;\n  duration: number;\n  timestamp: number;\n  success: boolean;\n  error?: string;\n}\n\ninterface APIPerformance {\n  endpoint: string;\n  method: string;\n  duration: number;\n  statusCode: number;\n  timestamp: number;\n  userId?: string;\n}\n\nclass PerformanceMonitor {\n  private metrics: PerformanceMetric[] = [];\n  private queryMetrics: QueryPerformance[] = [];\n  private apiMetrics: APIPerformance[] = [];\n  private readonly maxMetrics = 1000; // Keep last 1000 metrics in memory\n\n  // Generic performance tracking\n  async recordMetric(name: string, value: number, tags?: Record<string, string>): Promise<void> {\n    const metric: PerformanceMetric = {\n      name,\n      value,\n      timestamp: Date.now(),\n      tags,\n    };\n\n    this.metrics.push(metric);\n    \n    // Keep only recent metrics in memory\n    if (this.metrics.length > this.maxMetrics) {\n      this.metrics = this.metrics.slice(-this.maxMetrics);\n    }\n\n    // Store in cache for persistence\n    await cache.lpush(`metrics:${name}`, metric);\n    \n    // Keep only last 100 metrics per type in cache\n    const cached = await cache.lrange(`metrics:${name}`, 0, 99);\n    if (cached.length >= 100) {\n      await cache.del(`metrics:${name}`);\n      for (const m of cached.slice(0, 100)) {\n        await cache.lpush(`metrics:${name}`, m);\n      }\n    }\n  }\n\n  // Database query performance tracking\n  async recordQuery(query: string, duration: number, success: boolean, error?: string): Promise<void> {\n    const queryMetric: QueryPerformance = {\n      query: query.substring(0, 200), // Truncate long queries\n      duration,\n      timestamp: Date.now(),\n      success,\n      error,\n    };\n\n    this.queryMetrics.push(queryMetric);\n    \n    if (this.queryMetrics.length > this.maxMetrics) {\n      this.queryMetrics = this.queryMetrics.slice(-this.maxMetrics);\n    }\n\n    await cache.lpush('metrics:queries', queryMetric);\n    await this.recordMetric('db.query.duration', duration, { success: success.toString() });\n    \n    // Alert on slow queries\n    if (duration > 1000) { // 1 second\n      console.warn(`Slow query detected: ${duration}ms - ${query.substring(0, 100)}`);\n      await this.recordMetric('db.query.slow', 1, { duration: duration.toString() });\n    }\n  }\n\n  // API endpoint performance tracking\n  async recordAPI(\n    endpoint: string,\n    method: string,\n    duration: number,\n    statusCode: number,\n    userId?: string\n  ): Promise<void> {\n    const apiMetric: APIPerformance = {\n      endpoint,\n      method,\n      duration,\n      statusCode,\n      timestamp: Date.now(),\n      userId,\n    };\n\n    this.apiMetrics.push(apiMetric);\n    \n    if (this.apiMetrics.length > this.maxMetrics) {\n      this.apiMetrics = this.apiMetrics.slice(-this.maxMetrics);\n    }\n\n    await cache.lpush('metrics:api', apiMetric);\n    await this.recordMetric('api.request.duration', duration, {\n      endpoint,\n      method,\n      status: statusCode.toString(),\n    });\n\n    // Alert on slow API calls\n    if (duration > 2000) { // 2 seconds\n      console.warn(`Slow API call: ${method} ${endpoint} - ${duration}ms`);\n      await this.recordMetric('api.request.slow', 1, { endpoint, method });\n    }\n\n    // Track error rates\n    if (statusCode >= 400) {\n      await this.recordMetric('api.request.error', 1, {\n        endpoint,\n        method,\n        status: statusCode.toString(),\n      });\n    }\n  }\n\n  // Memory usage tracking\n  async recordMemoryUsage(): Promise<void> {\n    if (typeof process !== 'undefined' && process.memoryUsage) {\n      const memory = process.memoryUsage();\n      \n      await this.recordMetric('memory.heap.used', memory.heapUsed);\n      await this.recordMetric('memory.heap.total', memory.heapTotal);\n      await this.recordMetric('memory.rss', memory.rss);\n      await this.recordMetric('memory.external', memory.external);\n    }\n  }\n\n  // Cache performance tracking\n  async recordCacheHit(key: string): Promise<void> {\n    await this.recordMetric('cache.hit', 1, { key: key.substring(0, 50) });\n    await cache.incr('cache:hits:total');\n    await cache.incr(`cache:hits:${key}`);\n  }\n\n  async recordCacheMiss(key: string): Promise<void> {\n    await this.recordMetric('cache.miss', 1, { key: key.substring(0, 50) });\n    await cache.incr('cache:misses:total');\n    await cache.incr(`cache:misses:${key}`);\n  }\n\n  // Get performance statistics\n  async getMetrics(name?: string, limit: number = 100): Promise<PerformanceMetric[]> {\n    if (name) {\n      return await cache.lrange(`metrics:${name}`, 0, limit - 1);\n    } else {\n      return this.metrics.slice(-limit);\n    }\n  }\n\n  async getQueryMetrics(limit: number = 100): Promise<QueryPerformance[]> {\n    return await cache.lrange('metrics:queries', 0, limit - 1);\n  }\n\n  async getAPIMetrics(limit: number = 100): Promise<APIPerformance[]> {\n    return await cache.lrange('metrics:api', 0, limit - 1);\n  }\n\n  // Performance statistics\n  async getPerformanceStats(): Promise<{\n    api: {\n      avgResponseTime: number;\n      errorRate: number;\n      requestCount: number;\n    };\n    database: {\n      avgQueryTime: number;\n      slowQueryCount: number;\n      queryCount: number;\n    };\n    cache: {\n      hitRate: number;\n      totalHits: number;\n      totalMisses: number;\n    };\n    memory: {\n      heapUsed: number;\n      heapTotal: number;\n      rss: number;\n    };\n  }> {\n    const [apiMetrics, queryMetrics] = await Promise.all([\n      this.getAPIMetrics(100),\n      this.getQueryMetrics(100),\n    ]);\n\n    // API stats\n    const apiResponseTimes = apiMetrics.map(m => m.duration);\n    const apiErrors = apiMetrics.filter(m => m.statusCode >= 400).length;\n    const avgApiResponseTime = apiResponseTimes.length > 0 \n      ? apiResponseTimes.reduce((a, b) => a + b, 0) / apiResponseTimes.length \n      : 0;\n\n    // Database stats\n    const queryTimes = queryMetrics.map(m => m.duration);\n    const slowQueries = queryMetrics.filter(m => m.duration > 1000).length;\n    const avgQueryTime = queryTimes.length > 0 \n      ? queryTimes.reduce((a, b) => a + b, 0) / queryTimes.length \n      : 0;\n\n    // Cache stats\n    const totalHits = await cache.get('cache:hits:total') || 0;\n    const totalMisses = await cache.get('cache:misses:total') || 0;\n    const hitRate = totalHits + totalMisses > 0 \n      ? (totalHits / (totalHits + totalMisses)) * 100 \n      : 0;\n\n    // Memory stats (latest values)\n    const memoryMetrics = await this.getMetrics('memory.heap.used', 1);\n    const heapUsed = memoryMetrics.length > 0 ? memoryMetrics[0].value : 0;\n    \n    const heapTotalMetrics = await this.getMetrics('memory.heap.total', 1);\n    const heapTotal = heapTotalMetrics.length > 0 ? heapTotalMetrics[0].value : 0;\n    \n    const rssMetrics = await this.getMetrics('memory.rss', 1);\n    const rss = rssMetrics.length > 0 ? rssMetrics[0].value : 0;\n\n    return {\n      api: {\n        avgResponseTime: Math.round(avgApiResponseTime),\n        errorRate: apiMetrics.length > 0 ? Math.round((apiErrors / apiMetrics.length) * 100) : 0,\n        requestCount: apiMetrics.length,\n      },\n      database: {\n        avgQueryTime: Math.round(avgQueryTime),\n        slowQueryCount: slowQueries,\n        queryCount: queryMetrics.length,\n      },\n      cache: {\n        hitRate: Math.round(hitRate),\n        totalHits,\n        totalMisses,\n      },\n      memory: {\n        heapUsed: Math.round(heapUsed / 1024 / 1024), // Convert to MB\n        heapTotal: Math.round(heapTotal / 1024 / 1024),\n        rss: Math.round(rss / 1024 / 1024),\n      },\n    };\n  }\n\n  // Performance alerts\n  async checkPerformanceAlerts(): Promise<{\n    alerts: Array<{\n      type: string;\n      message: string;\n      severity: 'low' | 'medium' | 'high';\n      timestamp: number;\n    }>;\n  }> {\n    const alerts: Array<{\n      type: string;\n      message: string;\n      severity: 'low' | 'medium' | 'high';\n      timestamp: number;\n    }> = [];\n\n    const stats = await this.getPerformanceStats();\n\n    // Check API performance\n    if (stats.api.avgResponseTime > 2000) {\n      alerts.push({\n        type: 'api_slow',\n        message: `Average API response time is ${stats.api.avgResponseTime}ms`,\n        severity: 'high',\n        timestamp: Date.now(),\n      });\n    }\n\n    if (stats.api.errorRate > 10) {\n      alerts.push({\n        type: 'api_errors',\n        message: `API error rate is ${stats.api.errorRate}%`,\n        severity: 'high',\n        timestamp: Date.now(),\n      });\n    }\n\n    // Check database performance\n    if (stats.database.avgQueryTime > 500) {\n      alerts.push({\n        type: 'db_slow',\n        message: `Average database query time is ${stats.database.avgQueryTime}ms`,\n        severity: 'medium',\n        timestamp: Date.now(),\n      });\n    }\n\n    if (stats.database.slowQueryCount > 5) {\n      alerts.push({\n        type: 'db_slow_queries',\n        message: `${stats.database.slowQueryCount} slow queries detected`,\n        severity: 'medium',\n        timestamp: Date.now(),\n      });\n    }\n\n    // Check cache performance\n    if (stats.cache.hitRate < 70) {\n      alerts.push({\n        type: 'cache_low_hit_rate',\n        message: `Cache hit rate is ${stats.cache.hitRate}%`,\n        severity: 'low',\n        timestamp: Date.now(),\n      });\n    }\n\n    // Check memory usage\n    if (stats.memory.heapUsed > 500) { // 500MB\n      alerts.push({\n        type: 'memory_high',\n        message: `High memory usage: ${stats.memory.heapUsed}MB`,\n        severity: 'medium',\n        timestamp: Date.now(),\n      });\n    }\n\n    return { alerts };\n  }\n\n  // Start monitoring intervals\n  startMonitoring(intervalMs: number = 60000): void {\n    // Record memory usage every minute\n    setInterval(() => {\n      this.recordMemoryUsage();\n    }, intervalMs);\n\n    // Check for performance alerts every 5 minutes\n    setInterval(async () => {\n      const { alerts } = await this.checkPerformanceAlerts();\n      if (alerts.length > 0) {\n        console.warn('Performance alerts:', alerts);\n        // Here you could send alerts to monitoring service\n      }\n    }, intervalMs * 5);\n  }\n\n  // Utility function to measure execution time\n  async measureTime<T>(name: string, fn: () => Promise<T>): Promise<T> {\n    const start = Date.now();\n    try {\n      const result = await fn();\n      const duration = Date.now() - start;\n      await this.recordMetric(name, duration);\n      return result;\n    } catch (error) {\n      const duration = Date.now() - start;\n      await this.recordMetric(`${name}.error`, duration);\n      throw error;\n    }\n  }\n\n  // Decorator for measuring function performance\n  measurePerformance(name: string) {\n    return (target: any, propertyKey: string, descriptor: PropertyDescriptor) => {\n      const originalMethod = descriptor.value;\n      \n      descriptor.value = async function (...args: any[]) {\n        const start = Date.now();\n        try {\n          const result = await originalMethod.apply(this, args);\n          const duration = Date.now() - start;\n          await performanceMonitor.recordMetric(name, duration);\n          return result;\n        } catch (error) {\n          const duration = Date.now() - start;\n          await performanceMonitor.recordMetric(`${name}.error`, duration);\n          throw error;\n        }\n      };\n      \n      return descriptor;\n    };\n  }\n}\n\n// Create singleton instance\nconst performanceMonitor = new PerformanceMonitor();\n\n// Start monitoring\nperformanceMonitor.startMonitoring();\n\nexport { performanceMonitor };\nexport default performanceMonitor;\n"